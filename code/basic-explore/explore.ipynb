{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, random, math\n",
    "from datetime import datetime      # For timer \n",
    "import tarfile, zipfile            # Work with compressed files\n",
    "\n",
    "import numpy as np                 # Linear algebra\n",
    "import pandas as pd                # Data processing\n",
    "\n",
    "from IPython.display import display, Image  # Nice print statements\n",
    "from ggplot import *               # yhat/ggplot for plots\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        tmin, tsec = divmod((datetime.now() - start_time).total_seconds(), 60)\n",
    "        print(' Time taken: %i minutes and %s seconds.' %\n",
    "              (tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../../input/train.csv\")\n",
    "test_data = pd.read_csv(\"../../input/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine shape of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Dataset has {} samples with {} features each.\".format(*train_data.shape))\n",
    "train_data.info()\n",
    "display(train_data.head(5))\n",
    "\n",
    "print (\"Dataset has {} samples with {} features each.\".format(*test_data.shape))\n",
    "test_data.info()\n",
    "display(test_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine distrbutions of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train_data.columns\n",
    "features = [c for c in cols if c not in [\"id\", \"loss\"]]\n",
    "cat_features  = [c for c in cols if \"cat\" in c]\n",
    "cont_features = [c for c in cols if \"cont\" in c]\n",
    "\n",
    "print('Total {} features. {} category features, {} continuous features'.format(len(features), len(cat_features), len(cont_features)))\n",
    "\n",
    "display (train_data['loss'].describe())\n",
    "print (\"Mean/Variance values for cont_features:\")\n",
    "pd.concat( [train_data[cont_features].mean() , train_data[cont_features].var()], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(aes(x = 'loss'), train_data) + geom_density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if category values of test_data appear in train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_features:\n",
    "    vals_d = train_data[c].unique()\n",
    "    vals_t = test_data[c].unique()\n",
    "    missing_vals = [v for v in vals_t if v not in vals_d]\n",
    "    if len(missing_vals) > 0:\n",
    "        print (c, missing_vals)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine categories\n",
    "Combine categories from test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timer(None)\n",
    "ntrain = train_data.shape[0]\n",
    "ntest = test_data.shape[0]\n",
    "train_test = pd.concat((train_data[features], test_data[features])).reset_index(drop=True)\n",
    "for c in range(len(cat_features)):\n",
    "    train_test[cat_features[c]] = train_test[cat_features[c]].astype('category').cat.codes\n",
    "\n",
    "X = train_test.iloc[:ntrain,:]\n",
    "X_test = train_test.iloc[ntrain:,:]\n",
    "y = np.log(train_data['loss'])\n",
    "\n",
    "timer(start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start with some scikit-learn!\n",
    "How about a fast randomforestregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "# rfr = RandomForestRegressor(n_jobs=4, n_estimators=400, criterion='mse', verbose=1)\n",
    "# rfr = SGDRegressor(verbose = 0, n_iter = 1000)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "rfr = SVR(verbose = 1, max_iter = 1000)\n",
    "print('Starting now..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting now..')\n",
    "fit_time = timer(None)\n",
    "rfr.fit(scaler.fit_transform(X), y)\n",
    "timer(fit_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting now..')\n",
    "predict_time = timer(None)\n",
    "y_test = rfr.predict(scaler.transform(X_test))\n",
    "timer(predict_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly look at the outputs.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y_test)\n",
    "print(np.exp(y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to a csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../../input/sample_submission.csv')\n",
    "submission['loss'] = np.exp(y_test)\n",
    "if False:\n",
    "    submission_file = 'submission_rfr_mse_estimators_400.csv'\n",
    "    submission.to_csv(submission_file, index=None)\n",
    "    print('Saved to', submission_file)"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}